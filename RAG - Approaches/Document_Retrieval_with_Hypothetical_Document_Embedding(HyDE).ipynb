{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e37c2c-bf06-42af-8d55-52e193e9525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv \n",
    "!pip install langchain -U langchain-community \n",
    "!pip install PyMuPDF \n",
    "!pip install rank-bm25 \n",
    "!pip install deepeval \n",
    "!pip install langchain_ollama \n",
    "!pip install pypdf \n",
    "!pip install sentence-transformers \n",
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0541e-6559-4411-966c-fce220e7ebca",
   "metadata": {},
   "source": [
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "ollama serve\n",
    "\n",
    "ollama pull llama3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e8172f-5ac5-4c26-8e9a-769804884555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.schema import Document\n",
    "import textwrap\n",
    "import fitz\n",
    "import asyncio\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import List\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35865bb4-59db-4d83-bc9d-b028132adc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Vectorize Tab Replacement for Multiple Docs\n",
    "def replace_tabs_with_spaces(docs: List[Document]) -> List[Document]:\n",
    "    for doc in docs:\n",
    "        doc.page_content = doc.page_content.replace('\\t', ' ')\n",
    "    return docs\n",
    "\n",
    "\n",
    "# 2. Faster Text Wrapping Using List Comprehension\n",
    "def wrap_text_with_width(text: str, width=120) -> str:\n",
    "    return \"\\n\".join([text[i:i+width] for i in range(0, len(text), width)])\n",
    "\n",
    "\n",
    "# 3. Use Threading for Loading PDF and Vectorizing\n",
    "def pdf_to_vectorstore(path: str, chunk_size=1000, chunk_overlap=200) -> FAISS:\n",
    "    loader = PyPDFLoader(path)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Perform text splitting and cleaning in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len)\n",
    "        chunks = list(executor.map(lambda d: text_splitter.split_documents([d]), docs))\n",
    "\n",
    "    chunks = [item for sublist in chunks for item in sublist]  # Flatten the list\n",
    "    cleaned_chunks = replace_tabs_with_spaces(chunks)\n",
    "\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectorstore = FAISS.from_documents(cleaned_chunks, embeddings)\n",
    "    \n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# 4. Cache Document Contexts to Avoid Repeated Retrievals\n",
    "context_cache = {}\n",
    "\n",
    "def get_context_for_question(question: str, retriever) -> List[str]:\n",
    "    if question in context_cache:\n",
    "        return context_cache[question]\n",
    "\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "    context = [doc.page_content for doc in docs]\n",
    "    context_cache[question] = context\n",
    "    return context\n",
    "\n",
    "\n",
    "# 5. Async BM25 Retrieval for Faster Querying\n",
    "async def retrieve_with_bm25(bm25: BM25Okapi, texts: List[str], query: str, k: int = 5) -> List[str]:\n",
    "    query_tokens = query.split()\n",
    "    bm25_scores = bm25.get_scores(query_tokens)\n",
    "    top_k_indices = np.argsort(bm25_scores)[::-1][:k]\n",
    "    return [texts[i] for i in top_k_indices]\n",
    "\n",
    "\n",
    "# 6. Faster Retry Mechanism for Backoff\n",
    "async def retry_with_backoff(coroutine, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return await coroutine\n",
    "        except RateLimitError:\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            await asyncio.sleep(2 ** attempt + random.uniform(0, 1))\n",
    "\n",
    "\n",
    "# 7. Batch-Process Retrieval\n",
    "def batch_retrieve_context(questions: List[str], retriever) -> List[List[str]]:\n",
    "    return [get_context_for_question(q, retriever) for q in questions]\n",
    "\n",
    "\n",
    "# 8. Async Batch Answer Generation\n",
    "async def batch_generate_answers(questions: List[str], contexts: List[str], qa_chain) -> List[dict]:\n",
    "    tasks = []\n",
    "    for question, context in zip(questions, contexts):\n",
    "        input_data = {\"question\": question, \"context\": context}\n",
    "        tasks.append(qa_chain.invoke(input_data))\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return [{\"answer\": res.answer, \"context\": ctx, \"question\": q} for res, q, ctx in zip(results, questions, contexts)]\n",
    "\n",
    "\n",
    "# 9. Optimized Evaluation Using Numpy for Vector Operations\n",
    "def run_evaluation(retriever, num_questions: int = 5) -> None:\n",
    "    llm = initialize_llm_model()\n",
    "    qa_chain = create_qa_chain(llm)\n",
    "\n",
    "    with open(\"../data/q_a.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        q_a_data = json.load(file)\n",
    "\n",
    "    questions = [qa[\"question\"] for qa in q_a_data][:num_questions]\n",
    "    ground_truth_answers = [qa[\"answer\"] for qa in q_a_data][:num_questions]\n",
    "\n",
    "    # Batch process questions\n",
    "    retrieved_docs_batch = batch_retrieve_context(questions, retriever)\n",
    "    retrieved_contexts = [\" \".join(doc) for doc in retrieved_docs_batch]\n",
    "\n",
    "    # Async answer generation for all questions\n",
    "    loop = asyncio.get_event_loop()\n",
    "    generated_answers = loop.run_until_complete(batch_generate_answers(questions, retrieved_contexts, qa_chain))\n",
    "\n",
    "    # Score computations\n",
    "    correctness_scores = np.array([correctness_eval(g[\"answer\"], gt) for g, gt in zip(generated_answers, ground_truth_answers)])\n",
    "    faithfulness_scores = np.array([faithfulness_eval(g[\"answer\"], r) for g, r in zip(generated_answers, retrieved_docs_batch)])\n",
    "    relevance_scores = np.array([relevance_eval(q, g[\"answer\"]) for q, g in zip(questions, generated_answers)])\n",
    "\n",
    "    print(f\"Avg Correctness: {correctness_scores.mean()}\\nAvg Faithfulness: {faithfulness_scores.mean()}\\nAvg Relevance: {relevance_scores.mean()}\")\n",
    "\n",
    "\n",
    "# Define Correctness, Faithfulness, Relevance Evaluation\n",
    "def correctness_eval(generated_answer: str, ground_truth: str) -> float:\n",
    "    return 1.0 if generated_answer.strip().lower() == ground_truth.strip().lower() else 0.0\n",
    "\n",
    "\n",
    "def faithfulness_eval(generated_answer: str, retrieved_documents: List[str]) -> float:\n",
    "    context_string = \" \".join(retrieved_documents).lower()\n",
    "    return 1.0 if generated_answer.strip().lower() in context_string else 0.0\n",
    "\n",
    "\n",
    "def relevance_eval(question: str, generated_answer: str) -> float:\n",
    "    return 1.0 if question.lower() in generated_answer.lower() else 0.0\n",
    "\n",
    "\n",
    "# Initialize Ollama Model\n",
    "def initialize_llm_model():\n",
    "    return Ollama(model=\"llama3.1\", temperature=0)\n",
    "\n",
    "\n",
    "# Create the Question-Answer Chain\n",
    "def create_qa_chain(llm):\n",
    "    question_answer_prompt_template = \"\"\" \n",
    "    For the question below, provide a concise but suffice answer based ONLY on the provided context:\n",
    "    {context}\n",
    "    Question:\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    question_answer_prompt = PromptTemplate(template=question_answer_prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    question_answer_chain = question_answer_prompt | llm\n",
    "    return question_answer_chain\n",
    "\n",
    "\n",
    "# Read PDF Content to String\n",
    "def read_pdf_content(path: str) -> str:\n",
    "    doc = fitz.open(path)\n",
    "    content = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        content += page.get_text()\n",
    "    return content\n",
    "\n",
    "\n",
    "# HyDERetriever Class with Hypothetical Document Generation\n",
    "class HyDERetriever:\n",
    "    def __init__(self, files_path, chunk_size=500, chunk_overlap=100):\n",
    "        self.llm = initialize_llm_model()\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.vectorstore = pdf_to_vectorstore(files_path, chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "\n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"chunk_size\"],\n",
    "            template=\"\"\"Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
    "                        The document size should be exactly {chunk_size} characters.\"\"\",\n",
    "        )\n",
    "        self.hyde_chain = self.hyde_prompt | self.llm\n",
    "\n",
    "    def generate_hypothetical_document(self, query):\n",
    "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
    "        result = self.hyde_chain.invoke(input_variables)\n",
    "        return result if isinstance(result, str) else result.content\n",
    "\n",
    "    def retrieve(self, query, k=3):\n",
    "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "        similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
    "        return similar_docs, hypothetical_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3381a24d-3cee-44db-a293-bead0dea9ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypothetical Document:\n",
      "\n",
      "**Meta Platforms, Inc. Rebranding Report**\n",
      "\n",
      "**Executive Summary:**\n",
      "In October 2021, Facebook, Inc. rebranded to Meta Pla\n",
      "tforms, Inc., marking a significant shift in the company's identity. This report outlines the primary reasons behind thi\n",
      "s transformation.\n",
      "\n",
      "**Reasons for Rebranding:**\n",
      "\n",
      "1. **Expansion of Services:** The rebranding reflects Facebook's evoluti\n",
      "on into a comprehensive metaverse platform, encompassing virtual reality (VR), augmented reality (AR), and online social\n",
      " interactions.\n",
      "2. **Diversification of Business:** By separating the company name from its primary product, Meta Platfor\n",
      "ms, Inc. aims to distance itself from controversies surrounding Facebook, while emphasizing its broader technological am\n",
      "bitions.\n",
      "3. **Preparation for Emerging Technologies:** The rebranding positions the company for future growth in emergin\n",
      "g technologies like VR and AR, which are expected to play a significant role in shaping the digital landscape.\n",
      "\n",
      "**Conclu\n",
      "sion:**\n",
      "The rebranding of Facebook, Inc. to Meta Platforms, Inc. signifies a strategic shift towards a more comprehensiv\n",
      "e and forward-thinking identity, reflecting the company's commitment to innovation and technological advancement.\n",
      "\n",
      "Context 1:\n",
      "Facebook: A Comprehensive\n",
      "Introduction\n",
      "Facebook, now known as Meta Platforms, Inc., has dramatically transformed the way\n",
      " people \n",
      "interact and engage with digital content. Since its creation in 2004, the platform has evolved from a \n",
      "college \n",
      "project into a leading global technology company. This detailed overview covers \n",
      "Facebook’s history, services, leadershi\n",
      "p, location, workforce, and more.\n",
      "1. History and Foundation\n",
      "1.1 Origins and Early Development\n",
      "\n",
      "Context 2:\n",
      "and advertising drove its growth, culminating in a highly anticipated IPO on May 18, 2012. The \n",
      "IPO raised $16 billion, \n",
      "making it one of the largest tech IPOs in history and valuing Facebook at \n",
      "$104 billion.\n",
      "1.4 Evolution and Re branding\n",
      "I\n",
      "n October 2021, Facebook announced its rebranding to Meta Platforms, Inc., signaling a strategic \n",
      "shift towards building\n",
      " the “metaverse” — a collective virtual shared space created by the\n",
      "\n",
      "Context 3:\n",
      "strategies.\n",
      "2.6 Virtual and Augmented Reality\n",
      "Through its subsidiary Oculus, acquired in 2014, Facebook has ventured int\n",
      "o virtual reality (VR) \n",
      "and augmented reality (AR). Oculus produces VR headsets and related hardware, while Meta is \n",
      "inv\n",
      "esting in AR technologies to enhance digital interaction. The company aims to build a metaverse \n",
      "where users can interac\n",
      "t in a fully immersive digital environment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    path = path = \"/mnt/e/Virtual Agent/Doc/Facebook.pdf\"\n",
    "    retriever = HyDERetriever(path)\n",
    "\n",
    "    test_query = \"What were the primary reasons for Facebook's rebranding to Meta Platforms, Inc. in 2021?\"\n",
    "    results, hypothetical_doc = retriever.retrieve(test_query)\n",
    "\n",
    "    docs_content = [doc.page_content for doc in results]\n",
    "    print(\"Hypothetical Document:\\n\")\n",
    "    print(wrap_text_with_width(hypothetical_doc) + \"\\n\")\n",
    "\n",
    "    for i, doc in enumerate(docs_content):\n",
    "        print(f\"Context {i+1}:\\n{wrap_text_with_width(doc)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914dd15-6bca-4462-b123-a37f71e72256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
