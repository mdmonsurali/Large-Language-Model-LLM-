{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe343e7-b36a-44a4-8734-9863edd0d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain -U langchain-community\n",
    "!pip install langchain-elasticsearch \n",
    "!pip install sentence-transformers \n",
    "!pip install langchain-ollama \n",
    "!pip install python-docx \n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a85a7c-4349-4e06-9d57-9f8f189f73b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "import fitz\n",
    "from langchain.chains import RetrievalQA\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2a3ae3-c7eb-4f08-879b-5d68481cbf8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "template = \"\"\"You're Virtual Agent, name Genie.\n",
    "    {context}\n",
    "    Give answer what question you have. Answers will be max 50 words and concise, but you will always provide a full sentence. You will not provide extra out-of-context answers.\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "directory = \"/mnt/e/Virtual Agent/Doc\"\n",
    "\n",
    "# Step 1: Loading and splitting documents\n",
    "def load_docs(directory):\n",
    "    loader = DirectoryLoader(directory)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def split_docs(documents, chunk_size=200, chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "documents = load_docs(directory)\n",
    "docs = split_docs(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854c6c8e-97d2-41b2-b760-b957c99837fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:  5\n",
      "Number of chunks:  781\n"
     ]
    }
   ],
   "source": [
    "print('Number of documents: ', len(documents))\n",
    "print('Number of chunks: ', len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6032fb-4509-4d7c-a91d-eaeba4bb9f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Step 2: Creating embeddings and vector database\\ndef embedding_vectordb(docs):\\n    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\\n    vectordb = ElasticsearchStore.from_documents(\\n        docs,\\n        index_name=\"tt\",\\n        es_api_key=\"dlk3STJKRUJ3cGx2ejdYeURuSmY6azNVdnJIaDRTTXExcXFrN2I3NzE3Zw==\",\\n        embedding=embeddings,\\n        es_cloud_id=\"68b07e4d4a3e4955a67d84f374764fb0:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyRmMmI3M2Y2NTJiNzA0NjRkYTY1NmZiMDQwOGI3NDVlMiQ2ZDA2MjI0M2Q5Mzc0ODU4ODlhYTM3ZThjNTVjZmNmZQ==\"\\n    )\\n    return embeddings, vectordb\\n\\nembeddings, vectordb = embedding_vectordb(docs)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Step 2: Creating embeddings and vector database\n",
    "def embedding_vectordb(docs):\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectordb = ElasticsearchStore.from_documents(\n",
    "        docs,\n",
    "        index_name=\"tt\",\n",
    "        es_api_key=\"dlk3STJKRUJ3cGx2ejdYeURuSmY6azNVdnJIaDRTTXExcXFrN2I3NzE3Zw==\",\n",
    "        embedding=embeddings,\n",
    "        es_cloud_id=\"68b07e4d4a3e4955a67d84f374764fb0:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyRmMmI3M2Y2NTJiNzA0NjRkYTY1NmZiMDQwOGI3NDVlMiQ2ZDA2MjI0M2Q5Mzc0ODU4ODlhYTM3ZThjNTVjZmNmZQ==\"\n",
    "    )\n",
    "    return embeddings, vectordb\n",
    "\n",
    "embeddings, vectordb = embedding_vectordb(docs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb32d2c-7eae-4bcd-a44c-42791169eddf",
   "metadata": {},
   "source": [
    "### If you have already uploaded embeddings to Elastic Cloud, use the following code next time to prevent uploading duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa4143f1-cf3d-4066-96e5-ad4936e34c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Creating embeddings and vector database\n",
    "def embedding_vectordb():\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    vectordb = ElasticsearchStore(\n",
    "        embedding=embeddings,\n",
    "        index_name=\"tt\",\n",
    "        es_api_key=\"dlk3STJKRUJ3cGx2ejdYeURuSmY6azNVdnJIaDRTTXExcXFrN2I3NzE3Zw==\",\n",
    "        es_cloud_id=\"68b07e4d4a3e4955a67d84f374764fb0:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyRmMmI3M2Y2NTJiNzA0NjRkYTY1NmZiMDQwOGI3NDVlMiQ2ZDA2MjI0M2Q5Mzc0ODU4ODlhYTM3ZThjNTVjZmNmZQ==\"\n",
    "    )\n",
    "    return embeddings, vectordb\n",
    "\n",
    "embeddings, vectordb = embedding_vectordb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c11f517-2f19-420d-a59e-beedba5a3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Loading the model\n",
    "def load_model():\n",
    "    llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,)\n",
    "\n",
    "    return llm\n",
    "\n",
    "llm = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e7215f-37db-4736-8bdc-30f408c23131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_prompt_chain(llm, vectordb):\n",
    "    template = \"\"\"You're Virtual Agent, name Genie.\n",
    "    {context}\n",
    "    Give answer what question you have. Answers will be max 50 words and concise, but you will always provide a full sentence. You will not provide extra out-of-context answers.\n",
    "    Question: {question}\n",
    "    Answer:\"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "    chain_type_kwargs = {\"prompt\": prompt}\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        #chain_type=\"refine\",\n",
    "        retriever=retriever,\n",
    "        #return_source_documents=True,\n",
    "        chain_type_kwargs=chain_type_kwargs,\n",
    "    )\n",
    "    return chain\n",
    "\n",
    "def print_response(response: str):\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=100)))\n",
    "\n",
    "def get_response(chain, query):\n",
    "    start_time = time.time()\n",
    "    response = chain.run(query)\n",
    "    #print_response(response)\n",
    "    print(response)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken to generate answer: {elapsed_time:.2f} seconds\")\n",
    "    return response\n",
    "\n",
    "# Setup prompt and chain once\n",
    "chain = setup_prompt_chain(llm, vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484e0905-16ec-4edf-9f69-526e761f3f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Anderson is 38 years old.\n",
      "Time taken to generate answer: 1.06 seconds\n"
     ]
    }
   ],
   "source": [
    "# Ask a question\n",
    "#question = \"What are some of the key achievements John Anderson accomplished during his time at Everest Tech Solutions?\"\n",
    "\n",
    "question = \"How old are John Anderson?\"\n",
    "\n",
    "response = get_response(chain, question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00227a69-43bd-4c64-9b14-6598bc705323",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5ae56c-0731-41c3-b9b4-348df1c29e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Anderson is a 38-year-old American male with a successful career in finance and business management. Born and raised in Chicago, Illinois, John grew up in a family that valued education and hard'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How old are John Anderson?\"\n",
    "\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "\n",
    "# Check the length of the document\n",
    "len(docs)\n",
    "\n",
    "# Check the content of the first document\n",
    "docs[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03152fe7-8e83-44db-ab10-29e3b6cd6941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "John Anderson is a 38-year-old American male...\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Despite his demanding professional life, John Anderson is a dedicated family man. He is married to Laura Anderson, a talented graphic designer, and together they have two children: Emily, 10, and\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# Wrap our vectorstore with a compressor\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compressed_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "def display_relevant_documents(docs):\n",
    "    \"\"\"Formats and prints the relevant documents in a readable way.\"\"\"\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"Document {i}:\\n\\n{doc.page_content}\\n{'-' * 100}\")\n",
    "\n",
    "# Define the question to retrieve compressed documents\n",
    "question = \"How old is John Anderson?\"\n",
    "compressed_docs = compressed_retriever.get_relevant_documents(question)\n",
    "\n",
    "# Display the retrieved and compressed documents\n",
    "display_relevant_documents(compressed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b534fae-d791-4195-b882-61dbb47c5014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
